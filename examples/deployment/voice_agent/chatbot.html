<!DOCTYPE html>
<html>
<head>
    <title>Realtime Chatbot with AgentScope</title>
    <meta charset="UTF-8">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            max-width: 900px;
            margin: 0 auto;
            padding: 2rem;
            background: hsl(0, 0%, 98%);
            color: hsl(222.2, 84%, 4.9%);
            line-height: 1.5;
        }

        h1 {
            font-size: 2rem;
            font-weight: 600;
            margin-bottom: 1.5rem;
            color: hsl(222.2, 84%, 4.9%);
            letter-spacing: -0.025em;
        }

        #messages {
            border: 1px solid hsl(214.3, 31.8%, 91.4%);
            height: 400px;
            overflow-y: auto;
            padding: 1rem;
            margin: 1.5rem 0;
            background: hsl(0, 0%, 100%);
            border-radius: 0.5rem;
            box-shadow: 0 1px 3px 0 rgb(0 0 0 / 0.1), 0 1px 2px -1px rgb(0 0 0 / 0.1);
        }

        #messages::-webkit-scrollbar {
            width: 8px;
        }

        #messages::-webkit-scrollbar-track {
            background: hsl(210, 40%, 96.1%);
            border-radius: 4px;
        }

        #messages::-webkit-scrollbar-thumb {
            background: hsl(215.4, 16.3%, 56.9%);
            border-radius: 4px;
        }

        #messages::-webkit-scrollbar-thumb:hover {
            background: hsl(215.4, 16.3%, 46.9%);
        }

        input[type="text"] {
            width: 100%;
            padding: 0.625rem 0.875rem;
            font-size: 0.875rem;
            border: 1px solid hsl(214.3, 31.8%, 91.4%);
            border-radius: 0.375rem;
            background: hsl(0, 0%, 100%);
            color: hsl(222.2, 84%, 4.9%);
            transition: all 0.15s ease;
            outline: none;
        }

        input[type="text"]:focus {
            border-color: hsl(221.2, 83.2%, 53.3%);
            box-shadow: 0 0 0 3px hsl(221.2, 83.2%, 53.3%, 0.1);
        }

        textarea {
            width: 100%;
            min-height: 100px;
            padding: 0.625rem 0.875rem;
            font-size: 0.875rem;
            border: 1px solid hsl(214.3, 31.8%, 91.4%);
            border-radius: 0.375rem;
            background: hsl(0, 0%, 100%);
            color: hsl(222.2, 84%, 4.9%);
            transition: all 0.15s ease;
            outline: none;
            resize: vertical;
            font-family: inherit;
            line-height: 1.5;
        }

        textarea:focus {
            border-color: hsl(221.2, 83.2%, 53.3%);
            box-shadow: 0 0 0 3px hsl(221.2, 83.2%, 53.3%, 0.1);
        }

        button {
            display: inline-flex;
            align-items: center;
            justify-content: center;
            padding: 0.625rem 1rem;
            font-size: 0.875rem;
            font-weight: 500;
            border: none;
            border-radius: 0.375rem;
            cursor: pointer;
            transition: all 0.15s ease;
            background: hsl(222.2, 47.4%, 11.2%);
            color: hsl(210, 40%, 98%);
            box-shadow: 0 1px 2px 0 rgb(0 0 0 / 0.05);
        }

        button:hover {
            background: hsl(222.2, 47.4%, 15%);
        }

        button:active {
            transform: scale(0.98);
        }

        button:focus-visible {
            outline: 2px solid hsl(221.2, 83.2%, 53.3%);
            outline-offset: 2px;
        }

        .message {
            margin: 0.75rem 0;
            padding: 0.75rem 1rem;
            background: hsl(210, 40%, 98%);
            border-radius: 0.5rem;
            border: 1px solid hsl(214.3, 31.8%, 91.4%);
            font-size: 0.875rem;
        }

        .message strong {
            color: hsl(222.2, 47.4%, 11.2%);
            font-weight: 600;
        }

        .recording {
            background: hsl(0, 84.2%, 60.2%) !important;
            color: hsl(0, 0%, 100%) !important;
            animation: pulse 1.5s ease-in-out infinite;
        }

        @keyframes pulse {
            0%, 100% {
                opacity: 1;
                box-shadow: 0 0 0 0 hsl(0, 84.2%, 60.2%, 0.7);
            }
            50% {
                opacity: 0.9;
                box-shadow: 0 0 0 8px hsl(0, 84.2%, 60.2%, 0);
            }
        }

        .controls {
            display: flex;
            flex-wrap: wrap;
            gap: 0.75rem;
            margin: 1.5rem 0;
        }

        .configuration-container {
            background: hsl(0, 0%, 100%);
            padding: 1.5rem;
            border-radius: 0.5rem;
            margin: 1.5rem 0;
            border: 1px solid hsl(214.3, 31.8%, 91.4%);
            box-shadow: 0 1px 3px 0 rgb(0 0 0 / 0.1), 0 1px 2px -1px rgb(0 0 0 / 0.1);
        }

        .configuration-container h3 {
            font-size: 1.125rem;
            font-weight: 600;
            margin-bottom: 1rem;
            color: hsl(222.2, 84%, 4.9%);
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }

        .config-field {
            margin-bottom: 1.25rem;
        }

        .config-field:last-child {
            margin-bottom: 0;
        }

        .config-field label {
            display: block;
            font-weight: 500;
            margin-bottom: 0.5rem;
            color: hsl(222.2, 47.4%, 11.2%);
            font-size: 0.875rem;
        }

        .error-message {
            padding: 0.875rem 1rem;
            background: hsl(0, 84.2%, 95%);
            border: 1px solid hsl(0, 84.2%, 85%);
            border-radius: 0.5rem;
            margin: 1rem 0;
            display: none;
            color: hsl(0, 84.2%, 30%);
            font-size: 0.875rem;
            font-weight: 500;
            box-shadow: 0 1px 2px 0 rgb(0 0 0 / 0.05);
        }

        .text-input-container {
            display: flex;
            gap: 0.75rem;
            align-items: center;
            margin: 1.5rem 0;
        }

        .text-input-container input {
            flex: 1;
        }

        .text-input-container button {
            white-space: nowrap;
        }
    </style>
</head>
<body>
    <h1>Realtime Chatbot</h1>

    <div class="configuration-container">
        <h3>‚öôÔ∏è Configuration</h3>

        <div class="config-field">
            <label for="instructions">Instructions</label>
            <textarea id="instructions" placeholder="Enter agent instructions...">You're a helpful assistant named Friday.</textarea>
        </div>

        <div class="config-field">
            <label for="userId">User Name</label>
            <input type="text" id="userId" placeholder="Enter your name" value="User1" />
        </div>
    </div>

    <div id="errorMessage" class="error-message"></div>

    <div class="controls">
        <button id="voiceBtn" onclick="toggleVoice()">üé§ Start Recording</button>
        <button onclick="stopVoice()">‚èπÔ∏è Stop Recording</button>
        <button onclick="disconnect()">‚ùå Disconnect</button>
    </div>

    <div class="text-input-container">
        <input type="text" id="messageText" placeholder="Type a message..." />
        <button onclick="sendTextMessage()">üì§ Send</button>
    </div>

    <div id="messages"></div>

    <script>
        let ws = null;
        let audioContext = null;  // For recording, 16kHz
        let playbackAudioContext = null;  // For playback, 24kHz
        let mediaStream = null;
        let audioWorkletNode = null;
        let isRecording = false;
        let audioQueue = [];
        let isPlaying = false;
        let audioPlaybackNode = null;
        let audioPlaybackQueue = [];  // Store decoded Float32Array
        let audioPlaybackIndex = 0;
        let sessionId = "session1";  // Session ID
        let sessionCreated = false;  // Track if session has been created

        // Used to accumulate transcript text
        let currentTranscript = "";
        let currentTranscriptElement = null;
        let currentResponseTranscript = "";
        let currentResponseTranscriptElement = null;

        function showError(message) {
            const errorDiv = document.getElementById("errorMessage");
            errorDiv.innerText = message;
            errorDiv.style.display = "block";
            setTimeout(() => {
                errorDiv.style.display = "none";
            }, 5000);
        }

        async function connect() {
            const userId = document.getElementById("userId").value;
            ws = new WebSocket(`ws://localhost:8000/ws/${userId}/${sessionId}`);

            ws.onopen = function(event) {
                addMessage("System", "‚úÖ Connected to server, you can start voice conversation");
            };

            ws.onmessage = async function(event) {
                try {
                    const data = JSON.parse(event.data);
                    console.log("Received message:", data);

                    // Handle ServerEvents
                    switch (data.type) {
                        case "session_created":
                            sessionCreated = true;
                            addMessage("System", `‚úÖ Session created: ${data.session_id}`);
                            break;

                        case "agent_ready":
                            addMessage("System", `ü§ñ Agent ${data.agent_name} is ready`);
                            break;

                        case "response_created":
                            addMessage("System", `üí¨ Agent ${data.agent_name} started generating response...`);
                            break;

                        case "response_audio_delta":
                            // Receive audio data and add to playback queue
                            queueAudioChunk(data.delta);
                            break;

                        case "response_audio_done":
                            addMessage("System", "üîä Audio response completed");
                            break;

                        case "response_audio_transcript_delta":
                            // Agent response transcript text
                            appendResponseTranscript(data.agent_name, data.delta || "");
                            break;

                        case "response_audio_transcript_done":
                            // Complete Agent response transcript message
                            finishResponseTranscript();
                            break;

                        case "input_transcription_delta":
                            // User input transcript text
                            appendTranscript("You", data.delta || "");
                            break;

                        case "input_transcription_done":
                            appendTranscript("You", data.transcript || "");
                            // Complete user input transcript message
                            finishTranscript();
                            addMessage("System", `üìù User input recognition completed`);
                            break;

                        case "input_started":
                            addMessage("System", "üé§ Voice input started");
                            break;

                        case "input_done":
                            addMessage("System", "‚èπÔ∏è Voice input ended");
                            break;

                        case "response_done":
                            addMessage("System", `‚úÖ Response completed (input tokens: ${data.input_tokens}, output tokens: ${data.output_tokens})`);
                            break;

                        case "response_tool_use_delta":
                            addMessage("System", `üîß Tool call: ${data.name}`);
                            break;

                        case "response_tool_result":
                            addMessage("System", `‚úÖ Tool ${data.name} execution completed`);
                            break;

                        case "error":
                            addMessage("Error", `‚ùå ${data.error_type}: ${data.message}`);
                            break;

                        case "agent_ended":
                            addMessage("System", `üëã Agent ${data.agent_name} has ended`);
                            break;

                        case "session_ended":
                            addMessage("System", `üîö Session ${data.session_id} has ended`);
                            break;

                        default:
                            console.log("Unhandled event type:", data.type);
                            break;
                    }
                } catch (e) {
                    console.error("Error processing message:", e);
                }
            };

            ws.onclose = function(event) {
                addMessage("System", "‚ùå Disconnected");
                stopVoice();
                sessionCreated = false;  // Reset session state
            };

            ws.onerror = function(error) {
                addMessage("System", "‚ö†Ô∏è Connection error");
            };
        }

        async function toggleVoice() {
            if (!isRecording) {
                await startVoice();
            } else {
                stopVoice();
            }
        }

        async function startVoice() {
            try {
                // Validate instructions
                const instructions = document.getElementById("instructions").value.trim();
                if (!instructions) {
                    showError("‚ö†Ô∏è Instructions cannot be empty! Please enter instructions before recording.");
                    return;
                }

                // Check if WebSocket is connected
                if (!ws || ws.readyState !== WebSocket.OPEN) {
                    showError("‚ö†Ô∏è WebSocket is not connected! Please wait for connection.");
                    return;
                }

                // Send session create event if not already created
                if (!sessionCreated) {
                    const userName = document.getElementById("userId").value.trim();
                    addMessage("System", "üìù Creating session with instructions...");
                    ws.send(JSON.stringify({
                        type: "client_session_create",
                        config: {
                            instructions: instructions,
                            user_name: userName
                        }
                    }));

                    // Wait for session_created event before proceeding
                    // We'll set a timeout to wait for session creation
                    await new Promise((resolve, reject) => {
                        const timeout = setTimeout(() => {
                            reject(new Error("Session creation timeout"));
                        }, 5000);

                        const checkSession = setInterval(() => {
                            if (sessionCreated) {
                                clearTimeout(timeout);
                                clearInterval(checkSession);
                                resolve();
                            }
                        }, 100);
                    });
                }

                if (!audioContext) {
                    audioContext = new (
                    window.AudioContext || window.webkitAudioContext)({
                        sampleRate: 16000  // DashScope requires 16kHz
                    });
                }

                mediaStream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true,
                        sampleRate: 16000
                    }
                });

                const source = audioContext.createMediaStreamSource(
                mediaStream);

                // Use ScriptProcessorNode to process audio
                const processor = audioContext.createScriptProcessor(4096,
                1, 1);

                let audioChunkCount = 0;
                processor.onaudioprocess = function(e) {
                    if (!isRecording) return;

                    const inputData = e.inputBuffer.getChannelData(0);
                    const pcmData = convertToPCM16(inputData);
                    const base64Audio = arrayBufferToBase64(pcmData);

                    if (ws && ws.readyState === WebSocket.OPEN) {
                        audioChunkCount++;
                        if (audioChunkCount % 10 === 0) {
                            console.log(`Sending audio chunk ${audioChunkCount}`);
                        }
                        // Send ClientAudioAppendEvent
                        ws.send(JSON.stringify({
                            type: "client_audio_append",
                            session_id: sessionId,
                            audio: base64Audio,
                            format: {
                                sample_rate: 16000,
                                encoding: "pcm16"
                            }
                        }));
                    }
                };

                source.connect(processor);
                const dummyGain = audioContext.createGain();
                dummyGain.gain.value = 0;  // Mute to avoid feedback
                processor.connect(dummyGain);
                dummyGain.connect(audioContext.destination);

                isRecording = true;
                document.getElementById("voiceBtn").classList.add("recording");
                document.getElementById("voiceBtn").innerText = "üî¥ Recording...";
                addMessage("System", "üé§ Started recording...");

            } catch (err) {
                console.error("Failed to start recording:", err);
                if (err.message === "Session creation timeout") {
                    showError("‚ö†Ô∏è Session creation timeout. Please try again.");
                    addMessage("System", "‚ö†Ô∏è Session creation timeout");
                } else {
                    showError("‚ö†Ô∏è Unable to access microphone: " + err.message);
                    addMessage("System", "‚ö†Ô∏è Unable to access microphone: " + err.message);
                }
            }
        }

        function stopVoice() {
            isRecording = false;

            if (mediaStream) {
                mediaStream.getTracks().forEach(track => track.stop());
                mediaStream = null;
            }

            // Notify server that recording has stopped - send ClientAudioCommitEvent
            if (ws && ws.readyState === WebSocket.OPEN) {
                ws.send(JSON.stringify({
                    type: "client_audio_commit",
                    session_id: sessionId
                }));
            }

            document.getElementById("voiceBtn").classList.remove("recording");
            document.getElementById("voiceBtn").innerText = "üé§ Start Recording";
            addMessage("System", "‚èπÔ∏è Stopped recording");
        }

        function convertToPCM16(float32Array) {
            const int16Array = new Int16Array(float32Array.length);
            for (let i = 0; i < float32Array.length; i++) {
                const s = Math.max(-1, Math.min(1, float32Array[i]));
                int16Array[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
            }
            return int16Array.buffer;
        }

        function arrayBufferToBase64(buffer) {
            const bytes = new Uint8Array(buffer);
            let binary = '';
            for (let i = 0; i < bytes.byteLength; i++) {
                binary += String.fromCharCode(bytes[i]);
            }
            return btoa(binary);
        }

        function queueAudioChunk(base64Audio) {
            try {
                // Decode base64 audio data and convert to Float32Array
                const binaryString = atob(base64Audio);
                const bytes = new Uint8Array(binaryString.length);
                for (let i = 0; i < binaryString.length; i++) {
                    bytes[i] = binaryString.charCodeAt(i);
                }

                // Convert to Int16Array (PCM16), then to Float32Array
                const int16Array = new Int16Array(bytes.buffer);
                const float32Array = new Float32Array(int16Array.length);

                for (let i = 0; i < int16Array.length; i++) {
                    float32Array[i] = int16Array[i] / 32768.0;
                }

                // Add decoded audio data to queue
                audioPlaybackQueue.push(float32Array);

                // If not playing yet, start player
                if (!isPlaying) {
                    startAudioPlayback();
                }
            } catch (err) {
                console.error("Failed to decode audio chunk:", err);
            }
        }

        function startAudioPlayback() {
            if (isPlaying) return;

            try {
                // Create separate AudioContext for playback, using 24kHz sample rate
                if (!playbackAudioContext) {
                    playbackAudioContext = new (window.AudioContext ||
                    window.webkitAudioContext)({
                        sampleRate: 24000  // DashScope outputs 24kHz
                    });
                }

                // If AudioContext is suspended (browser policy), resume it
                if (playbackAudioContext.state === 'suspended') {
                    playbackAudioContext.resume();
                }

                isPlaying = true;
                audioPlaybackIndex = 0;

                // Use ScriptProcessorNode for streaming playback
                const bufferSize = 4096;
                const processor =
                playbackAudioContext.createScriptProcessor(bufferSize, 0, 1);

                processor.onaudioprocess = function(e) {
                    const output = e.outputBuffer.getChannelData(0);
                    const samplesNeeded = output.length;
                    let samplesWritten = 0;

                    // Get audio data from queue and fill output buffer
                    while (samplesWritten < samplesNeeded &&
                    audioPlaybackQueue.length > 0) {
                        const chunk = audioPlaybackQueue[0];

                        // Calculate number of samples to read from current chunk
                        const samplesToRead = Math.min(
                            samplesNeeded - samplesWritten,
                            chunk.length - audioPlaybackIndex
                        );

                        // Directly copy Float32 data to output
                        for (let i = 0; i < samplesToRead; i++) {
                            output[samplesWritten + i] = chunk[
                            audioPlaybackIndex + i];
                        }

                        samplesWritten += samplesToRead;
                        audioPlaybackIndex += samplesToRead;

                        // If current chunk is finished, remove it and reset index
                        if (audioPlaybackIndex >= chunk.length) {
                            audioPlaybackQueue.shift();
                            audioPlaybackIndex = 0;
                        }
                    }

                    // If queue is empty and no more data, fill with silence
                    if (samplesWritten < samplesNeeded) {
                        for (let i = samplesWritten; i < samplesNeeded; i++) {
                            output[i] = 0;
                        }

                        // If queue continues to be empty for a while, stop playback
                        if (audioPlaybackQueue.length === 0) {
                            setTimeout(() => {
                                if (audioPlaybackQueue.length === 0) {
                                    stopAudioPlayback();
                                }
                            }, 100);
                        }
                    }
                };

                processor.connect(playbackAudioContext.destination);
                audioPlaybackNode = processor;

            } catch (err) {
                console.error("Failed to start audio playback:", err);
                isPlaying = false;
            }
        }

        function stopAudioPlayback() {
            if (audioPlaybackNode) {
                audioPlaybackNode.disconnect();
                audioPlaybackNode = null;
            }
            isPlaying = false;
            audioPlaybackQueue = [];
            audioPlaybackIndex = 0;
        }

        function sendTextMessage() {
            const input = document.getElementById("messageText");
            if (ws && input.value) {
                ws.send(JSON.stringify({
                    type: "client_text_append",
                    session_id: sessionId,
                    text: input.value
                }));
                addMessage("You", input.value);
                input.value = '';
            }
        }

        function disconnect() {
            stopVoice();
            stopAudioPlayback();
            if (ws) {
                ws.close();
            }
            sessionCreated = false;  // Reset session state
        }


        function addMessage(sender, message) {
            const messagesDiv = document.getElementById("messages");
            const messageDiv = document.createElement("div");
            messageDiv.className = "message";
            const time = new Date().toLocaleTimeString();
            messageDiv.innerHTML = `<strong>[${time}] ${sender}:</strong>
            ${message}`;
            messagesDiv.appendChild(messageDiv);
            messagesDiv.scrollTop = messagesDiv.scrollHeight;
        }

        function appendTranscript(sender, text) {
            const messagesDiv = document.getElementById("messages");

            // If there's no current message element yet, create a new one
            if (!currentTranscriptElement) {
                currentTranscript = "";
                currentTranscriptElement = document.createElement("div");
                currentTranscriptElement.className = "message";
                const time = new Date().toLocaleTimeString();
                currentTranscriptElement.innerHTML = `<strong>[${time}] ${
                sender}:</strong> <span class="transcript-content"></span>`;
                messagesDiv.appendChild(currentTranscriptElement);
            }

            // Accumulate text
            currentTranscript += text;

            // Update displayed content
            const contentSpan = currentTranscriptElement.querySelector(
            '.transcript-content');
            if (contentSpan) {
                contentSpan.textContent = currentTranscript;
            }

            // Scroll to bottom
            messagesDiv.scrollTop = messagesDiv.scrollHeight;
        }

        function finishTranscript() {
            // Complete current transcript message, prepare for next one
            currentTranscript = "";
            currentTranscriptElement = null;
        }

        function appendResponseTranscript(sender, text) {
            const messagesDiv = document.getElementById("messages");

            // If there's no current response message element yet, create a new one
            if (!currentResponseTranscriptElement) {
                currentResponseTranscript = "";
                currentResponseTranscriptElement = document.createElement("div");
                currentResponseTranscriptElement.className = "message";
                const time = new Date().toLocaleTimeString();
                currentResponseTranscriptElement.innerHTML = `<strong>[${time}] ${sender}:</strong> <span class="response-transcript-content"></span>`;
                messagesDiv.appendChild(currentResponseTranscriptElement);
            }

            // Accumulate text
            currentResponseTranscript += text;

            // Update displayed content
            const contentSpan = currentResponseTranscriptElement.querySelector('.response-transcript-content');
            if (contentSpan) {
                contentSpan.textContent = currentResponseTranscript;
            }

            // Scroll to bottom
            messagesDiv.scrollTop = messagesDiv.scrollHeight;
        }

        function finishResponseTranscript() {
            // Complete current response transcript message, prepare for next one
            currentResponseTranscript = "";
            currentResponseTranscriptElement = null;
        }

        // Send message with Enter key
        document.getElementById("messageText").addEventListener("keypress",
         function(event) {
            if (event.key === "Enter") {
                sendTextMessage();
            }
        });

        // Auto-connect when page loads
        window.onload = connect;
    </script>
</body>
</html>